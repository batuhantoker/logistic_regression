{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of elements: \t\t177\n",
      "total number of classes: \t\t3\n",
      "number of identical elements: \t\t140.0\n",
      "number of different elements: \t\t37.0\n",
      "percentage of identical elements: \t79.10%\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "from random import shuffle\n",
    "\n",
    "def normalize(dataset):\n",
    "    asd = np.array(dataset)\n",
    "    for i in range(1,3):\n",
    "        asd[:,i]=list(map(lambda x: (x-max(dataset.values[:,i]))/(max(dataset.values[:,i])-min(dataset.values[:,i])), dataset.values[:,i]))\n",
    "    return asd\n",
    "\n",
    "def logLikelihood(omega,dataset):\n",
    "    df= pandas.DataFrame(dataset) \n",
    "    a = np.array(np.zeros(((dataset).shape[0])))\n",
    "    d = np.array(np.zeros(((dataset).shape[0])))\n",
    "    y = df.values[:,0]\n",
    "    for i in range(df.shape[0]-1):\n",
    "        for j in range(df.shape[1]-2):\n",
    "            a[j] = omega[j]*df.values[i,j]\n",
    "        d[i] = y[i]*(omega[0]+a.sum())-np.log(1+np.exp(omega[0]+a.sum()))\n",
    "    return d.sum()\n",
    "        \n",
    "def parameter(omega,dataset):\n",
    "    asd = np.array(np.zeros(((dataset).shape[0])))\n",
    "    d= np.array(omega)\n",
    "    a = np.array(np.zeros(((dataset).shape[0])))\n",
    "    y = pandas.DataFrame(dataset).values[:,0]\n",
    "    for j in range(pandas.DataFrame(dataset).shape[1]-1):\n",
    "        for i in range(pandas.DataFrame(dataset).shape[0]-1):\n",
    "            a[j] = omega[j]*pandas.DataFrame(dataset).values[i,j]\n",
    "            if j==0:\n",
    "                asd[i] = y[i]-(np.exp(omega[0]+a.sum())/(1+np.exp(omega[0]+a.sum())))\n",
    "            else:\n",
    "                asd[i] = pandas.DataFrame(dataset).values[i,j+1]*(y[i]-((np.exp(omega[0]+a.sum()))/(1+np.exp(omega[0]+a.sum()))))\n",
    "            d[j]=asd.sum()\n",
    "    return d\n",
    "\n",
    "def score(omega,dataset):\n",
    "    df= dataset\n",
    "    scr=np.array(np.zeros(((dataset).shape[0])))\n",
    "    for i in range(df.shape[0]-1):\n",
    "        scr[i]=omega[0]+df[i,1]*omega[1]+df[i,2]*omega[2]+df[i,3]*omega[3]\n",
    "    return np.exp(scr)/(1+np.exp(scr))\n",
    "\n",
    "def scoreEvaluation(score,minimum):\n",
    "    scr=np.array(np.zeros((len(score))))                      \n",
    "    for i in range(len(score)):\n",
    "        if score[i]<minimum:\n",
    "            scr[i]=0\n",
    "        else:\n",
    "            scr[i]=1\n",
    "    return scr\n",
    "def evaluatePrediction(test,train):\n",
    "    x = pandas.DataFrame(np.zeros(test.shape[0]-1))\n",
    "    for i in range(test.shape[0]-1):\n",
    "        x.values[i]=(test[i,0]==train[i]).astype(int)\n",
    "    return x\n",
    "\n",
    "def gradientAscent(omega,rate,dataset,iterations):\n",
    "    for i in range(iterations):#while  iters < max_iters: # all(i >= precision for i in previous_step_size) and\n",
    "        #  and  previous_step_size[1] > precision and previous_step_size[2] > precision and previous_step_size[3] > precision  and\n",
    "        prev_omega = omega #Store current x value in prev_x\n",
    "        omega = prev_omega + rate * parameter(prev_omega,dataset)  #Grad ascent\n",
    "        #iters = iters+1 #iteration count\n",
    "        #print(omega)\n",
    "    return omega\n",
    "\n",
    "#handle data\n",
    "titanic_Data=pandas.read_csv('titanicdata.csv')#,skiprows=lambda x: x not in pandas.Series(range(1,800)))\n",
    "titanic_Data=normalize(titanic_Data)\n",
    "number_of_rows = titanic_Data.shape[0]\n",
    "index = list(np.arange(number_of_rows))\n",
    "np.random.shuffle(index)\n",
    "random_data=titanic_Data\n",
    "for l in range(len(index)):\n",
    "    random_data[l,:]=titanic_Data[index[l],:]\n",
    "titanic_Data=random_data\n",
    "train_data=np.take(titanic_Data, range(round(titanic_Data.shape[0]*0.6)), axis=0)\n",
    "valid_data=np.take(titanic_Data, range(round(titanic_Data.shape[0]*0.6),round(titanic_Data.shape[0]*0.6)+round(titanic_Data.shape[0]*0.2)), axis=0)\n",
    "test_data=np.take(titanic_Data, range(round(titanic_Data.shape[0]*0.8),round(titanic_Data.shape[0]*0.6)+round(titanic_Data.shape[0]*0.2)+round(titanic_Data.shape[0]*0.2)), axis=0)\n",
    "#test_data\n",
    "omega=[0,0,0,0] #initial values for omega\n",
    "omega=gradientAscent(omega,0.00001,train_data,190)\n",
    "scor=score(omega,test_data)\n",
    "prediction=scoreEvaluation(scor,0.5)\n",
    "evaluation=evaluatePrediction(test_data,prediction)\n",
    "number_of_equal_elements = np.sum(evaluation)\n",
    "total_elements = (evaluation.shape[0])\n",
    "percentage = number_of_equal_elements[0]/total_elements\n",
    "number_of_class=test_data.shape[1]-1\n",
    "print('total number of elements: \\t\\t{}'.format(total_elements))\n",
    "print('total number of classes: \\t\\t{}'.format(number_of_class))\n",
    "print('number of identical elements: \\t\\t{}'.format(number_of_equal_elements[0]))\n",
    "print('number of different elements: \\t\\t{}'.format(total_elements-number_of_equal_elements[0]))\n",
    "print('percentage of identical elements: \\t{:.2f}%'.format(percentage*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -0.30259989,  -0.88638236, -76.82101482,   0.        ])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of elements: \t\t177\n",
      "total number of classes: \t\t3\n",
      "number of identical elements: \t\t119.0\n",
      "number of different elements: \t\t58.0\n",
      "percentage of identical elements: \t67.23%\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
